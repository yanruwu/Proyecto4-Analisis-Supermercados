# ComparaciÃ³n y AnÃ¡lisis de Precios de Supermercados en EspaÃ±a ğŸ›’

## DescripciÃ³n del Proyecto

Este proyecto busca analizar la variabilidad y evoluciÃ³n de precios de productos bÃ¡sicos en seis grandes supermercados de EspaÃ±a (Alcampo, Carrefour, Dia, Eroski, Hipercor y Mercadona) a partir de datos recolectados de la plataforma [FACUA: Precios Supermercados](https://super.facua.org/). FACUA ofrece datos actualizados diariamente sobre precios de productos, permitiendo a los usuarios comparar y observar fluctuaciones de precio. AquÃ­ empleamos herramientas de scraping y procesamiento de datos para crear una base de datos en SQL, analizar la informaciÃ³n y generar visualizaciones para obtener conclusiones claras sobre tendencias y prÃ¡cticas de precios en los supermercados.

## Objetivos EspecÃ­ficos

1. **Scraping de datos**: Extraer informaciÃ³n detallada de productos y precios.
2. **Almacenamiento estructurado**: Crear una base de datos en SQL para organizar los datos.
3. **AnÃ¡lisis de datos**:
   - ComparaciÃ³n de precios entre supermercados.
   - EvaluaciÃ³n de la evoluciÃ³n temporal de precios.
   - DetecciÃ³n de anomalÃ­as de precios.
   - AnÃ¡lisis de dispersiÃ³n y comparaciÃ³n de precios promedio.
4. **VisualizaciÃ³n de datos**: Crear grÃ¡ficos para comunicar los resultados.

## Estructura del Proyecto

```
â”œâ”€â”€ datos/                  # Archivos CSV y datos en crudo
â”‚   â”œâ”€â”€ df_complete.csv      # Archivo csv con todos los datos recopilados
â”œâ”€â”€ notebooks/              # Notebooks Jupyter para EDA y anÃ¡lisis especÃ­ficos
â”‚   â”œâ”€â”€ 1-scraping.ipynb    # Scrapeo de la web de facua
â”‚   â”œâ”€â”€ 2-ddbb_creation     # CreaciÃ³n de la BBDD e inserciÃ³n de valores
â”‚   â”œâ”€â”€ 3-analysis          # AnÃ¡lisis de los datos y visualizaciones
â”œâ”€â”€ scripts/                # Scripts de scraping y procesamiento de datos
â”‚   â”œâ”€â”€ scraping_funcs.py   # Funciones para scrapeo
â”‚   â”œâ”€â”€ query_funcs.py      # Funciones para ejecutar queries SQL desde python
â”‚   â”œâ”€â”€ analysis_funcs.py   # Funciones usadas para el anÃ¡lisis de los datos
â”œâ”€â”€ environment.yml         # Archivo de configuraciÃ³n para gestionar dependencias del entorno
â””â”€â”€ README.md               # DocumentaciÃ³n del proyecto
```

## InstalaciÃ³n y Requisitos

Para configurar el entorno de desarrollo y asegurarte de que todas las dependencias necesarias estÃ©n instaladas, sigue estos pasos:

### Requisitos

- Python 3.7 o superior ğŸ
- [Anaconda](https://www.anaconda.com/products/distribution) o [Miniconda](https://docs.conda.io/en/latest/miniconda.html) (opcional, pero recomendado)

### Paquetes Necesarios

El proyecto utiliza los siguientes paquetes:

- [`pandas`](https://pandas.pydata.org/pandas-docs/stable/): Para la manipulaciÃ³n y anÃ¡lisis de datos.
- [`numpy`](https://numpy.org/doc/stable/): Para operaciones numÃ©ricas y manejo de arrays.
- [`matplotlib`](https://matplotlib.org/stable/users/index.html): Para la visualizaciÃ³n de datos.
- [`seaborn`](https://seaborn.pydata.org/): Para visualizaciÃ³n estadÃ­stica de datos.
- [`plotly`](https://plotly.com/python/): Para grÃ¡ficos interactivos.
- [`tqdm`](https://tqdm.github.io/): Para mostrar barras de progreso en loops.
- [`psycopg2`](https://www.psycopg.org/): Para conectar Python con PostgreSQL.
- [`BeautifulSoup`](https://www.crummy.com/software/BeautifulSoup/bs4/doc/): Para el scraping de datos.
- [`requests`](https://docs.python-requests.org/en/latest/): Para realizar solicitudes HTTP sencillas.

### InstalaciÃ³n

1. **Clona el repositorio:**

   ```bash
   git clone https://github.com/yanruwu/Proyecto4-Analisis-Supermercados
   cd Proyecto4-Analisis-Supermercados
2. **Crea un entorno virtual:**

    Para crear el entorno de Conda, usa el siguiente comando:
    ```bash
    conda env create -f environment.yml
    ```
    O si prefieres usar venv:
    ```bash
    python -m venv venv
    source venv/bin/activate  # En macOS/Linux
    venv\Scripts\activate     # En Windows
    ```
    